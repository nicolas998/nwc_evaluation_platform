{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f38fb6d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-15T20:17:32.510894Z",
     "start_time": "2022-11-15T20:17:30.243147Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import argparse\n",
    "import pandas as pd \n",
    "import netCDF4\n",
    "\n",
    "\n",
    "\n",
    "def get_parent_flow(usgs_id, year):\n",
    "    #Get the list of parents from the csv \n",
    "    a = usgs_p.loc[usgs_id, 'from_usgs']\n",
    "    parents = np.array(a[1:-1].split(','))\n",
    "    \n",
    "    #Get the flow data from the parents\n",
    "    flow_parents = []\n",
    "    existing_childs = []\n",
    "    for parent in parents:\n",
    "        try:\n",
    "            qo = np.load('/mnt/y/flow/USGS_observed/%d/%d_usgs_%s.npz' % (year, year,parent))\n",
    "            uxt_u = np.unique(qo['data']['uxt'])\n",
    "            #Converts the observed flow to match the nwc forecast\n",
    "            flow_o = np.ones(d.dimensions['issue_time'].size)*-999\n",
    "            shared1 = np.argwhere(np.in1d(uxt, uxt_u)).T[0]\n",
    "            shared2 = np.argwhere(np.in1d(uxt_u, uxt)).T[0]\n",
    "            flow_o[shared1] = qo['data']['val'][shared2]*0.028\n",
    "            flow_o[flow_o <= 0] = np.nan\n",
    "            flow_parents.append(flow_o)\n",
    "            existing_childs.append(parent)\n",
    "        except:\n",
    "            pass\n",
    "    flow_parents = np.array(flow_parents)\n",
    "    parents_sum = flow_parents.sum(axis = 0)\n",
    "    \n",
    "    qo = np.load('/mnt/y/flow/USGS_observed/%d/%d_usgs_%s.npz' % (year, year,usgs_id))\n",
    "    uxt_u = np.unique(qo['data']['uxt'])\n",
    "    #Converts the observed flow to match the nwc forecast\n",
    "    flow_o = np.ones(d.dimensions['issue_time'].size)*-999\n",
    "    shared1 = np.argwhere(np.in1d(uxt, uxt_u)).T[0]\n",
    "    shared2 = np.argwhere(np.in1d(uxt_u, uxt)).T[0]\n",
    "    flow_o[shared1] = qo['data']['val'][shared2]*0.028\n",
    "    flow_o[flow_o <= 0] = np.nan\n",
    "    \n",
    "    flow_scaled = np.nanmean(flow_o) * (parents_sum / np.nanmean(parents_sum))\n",
    "    \n",
    "    #Computes the errors of using the persistence \n",
    "    Ep = []\n",
    "    Es = []\n",
    "    for lead in range(1,19):\n",
    "        a = 100*(parents_sum-np.roll(flow_o,lead))/np.roll(flow_o,lead)\n",
    "        Ep.append(a.astype(int))\n",
    "        a = 100*(flow_scaled-np.roll(flow_o,lead))/np.roll(flow_o,lead)\n",
    "        Es.append(a.astype(int))\n",
    "    \n",
    "    results = {\n",
    "        'childs': existing_childs,\n",
    "        'flow': flow_o,\n",
    "        'flow_childs':flow_parents,\n",
    "        'sum_childs':parents_sum,\n",
    "        'scaled_childs': flow_scaled,\n",
    "        'er_chi': Ep,\n",
    "        'er_sca': Es\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "year = 2022\n",
    "\n",
    "usgs_p = pd.read_csv('../data/usgs_parents_v2.csv', usecols=[1,4],dtype = {'to_usgs':str,'from_usgs':'str'}, index_col=0)\n",
    "d = netCDF4.Dataset('/mnt/y/flow/NWC_forecast/%d_nwc_short.nc' % year)\n",
    "usgs = d['usgs_id'][:]\n",
    "uxt = d['issue_time'][:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e8d4da8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-15T20:22:13.804811Z",
     "start_time": "2022-11-15T20:20:46.257455Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 01030350 0\n",
      "1 01030500 1\n",
      "2 06741510 0\n",
      "3 402114105350101 0\n",
      "4 272524080221800 0\n"
     ]
    }
   ],
   "source": [
    "real_childs = {}\n",
    "for pos, gauge in enumerate(usgs_p.index.values[:5]):\n",
    "    try:\n",
    "        childs = get_parent_flow(gauge, year)\n",
    "#         error_simple[pos,:,:] = childs['er_chi']\n",
    "#         error_scaled[pos,:,:] = childs['er_sca']\n",
    "#         per_simple[pos,:] = childs['sum_childs']*100\n",
    "#         per_scaled[pos,:] = childs['scaled_childs']*100\n",
    "        real_childs.update({gauge:childs['childs']})\n",
    "        real_childs[gauge] = '{' +','.join(real_childs[gauge]) + '}'\n",
    "        print(pos, usgs[pos], 0)\n",
    "    except:\n",
    "        print(pos, usgs[pos], 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5dbe4e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
